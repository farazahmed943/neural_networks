{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "if not os.path.exists('names.txt'):\n",
    "    !wget \"https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt\"\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading training data\n",
    "words =  open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# Create training set for the bigrams\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "target: tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1]])\n",
      "label tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size= 3\n",
    "\n",
    "# The X are the input for the neural net and Y is the labels corresponding to X\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix= stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] \n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "print('target:',X)\n",
    "print('label',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.int64, torch.Size([5]), torch.int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,X.dtype,Y.shape,Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn(27,2)\n",
    "# This contains the embedding representation of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4903, -0.1670])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[stoi['e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4903, -0.1670])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try the one hot method and see if we are getting similiar results or not\n",
    "F.one_hot(torch.tensor(stoi['e']),num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6951,  0.5885],\n",
       "         [ 0.6951,  0.5885],\n",
       "         [ 0.6951,  0.5885]],\n",
       "\n",
       "        [[ 0.6951,  0.5885],\n",
       "         [ 0.6951,  0.5885],\n",
       "         [ 0.4903, -0.1670]],\n",
       "\n",
       "        [[ 0.6951,  0.5885],\n",
       "         [ 0.4903, -0.1670],\n",
       "         [-1.0997, -0.6135]],\n",
       "\n",
       "        [[ 0.4903, -0.1670],\n",
       "         [-1.0997, -0.6135],\n",
       "         [-1.0997, -0.6135]],\n",
       "\n",
       "        [[-1.0997, -0.6135],\n",
       "         [-1.0997, -0.6135],\n",
       "         [ 0.7726,  0.4719]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding our X\n",
    "C[X]\n",
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd = C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tanh layer\n",
    "W1 = torch.randn(6,100)\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (15x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43memd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m \u001b[38;5;241m+\u001b[39m b1\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (15x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "emd @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above resulted in error because the embeddings are stacked up in the dimension (5,3,2) we need to somehow concatenate it\n",
    "\n",
    "# First Way\n",
    "# plucking out individual rows for each dimension\n",
    "[emd[:,0,:], emd[:,1,:], emd[:,2,:]]\n",
    "\n",
    "#concatenating them on axis=1\n",
    "torch.cat([emd[:,0,:], emd[:,1,:], emd[:,2,:]],1).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second Way\n",
    "# it takes the parameter that acts as a dimension on which you want the values. It spits out an list of tensors containing that exact information\n",
    "torch.unbind(emd,1)\n",
    "\n",
    "\n",
    "#concat it through dimension 1\n",
    "torch.concat(torch.unbind(emd,1),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is the above way in efficient?\n",
    "a = torch.arange(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When we called a.view(3,3,2) on it the attributes of the tensor works internally to reflect that tensor as shape(3,3,2) \\nbut underlying storage doesn't change that means the no new memory is created for this operation and this \\nthe exact reason why torch.unbind was not an efficient choice as concatenation of tension will always create a new memory.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''When we called a.view(3,3,2) on it the attributes of the tensor works internally to reflect that tensor as shape(3,3,2) \n",
    "but underlying storage doesn't change that means the no new memory is created for this operation and this \n",
    "the exact reason why torch.unbind was not an efficient choice as concatenation of tension will always create a new memory.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = emd.view(5,6)@ W1 + b1\n",
    "# To make it more dynamic let's fetch the shape of tensor from the tensor itself\n",
    "\n",
    "h = emd.view(emd.shape[0],6) @ W1 + b1\n",
    "\n",
    "# If we give -1 then it interprets the dimension on its own\n",
    "h = emd.view(-1,6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The softmax layer\n",
    "# The input will be the output of previous layer that will be 100 hence my softmax layer will take input of 100 and \n",
    "# since we this is the last layer we want it to represent the characters that will ne represented by neurons in our case it will be 27\n",
    "W2 = torch.randn(100,27)\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logits\n",
    "logits = h @ W2 + b2\n",
    "counts = logits.exp()\n",
    "probs = counts/counts.sum(1,keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0722e-13, 1.9058e-10, 1.1091e-18, 6.7012e-08, 1.5597e-10, 2.7795e-23,\n",
       "         7.1728e-28, 5.5383e-30, 8.7077e-22, 5.6067e-25, 1.9316e-04, 5.7447e-12,\n",
       "         1.1414e-07, 3.0389e-23, 2.0979e-28, 9.9959e-01, 8.0854e-13, 9.1878e-09,\n",
       "         2.2304e-17, 3.0658e-10, 4.8815e-06, 9.7131e-16, 4.1470e-08, 1.7691e-25,\n",
       "         1.5031e-15, 2.1425e-04, 1.3438e-25],\n",
       "        [4.3870e-08, 2.5043e-09, 1.8327e-21, 1.8688e-09, 1.2603e-06, 3.8913e-19,\n",
       "         4.0859e-29, 5.0054e-25, 2.0458e-21, 4.6420e-22, 4.2432e-01, 1.4125e-09,\n",
       "         1.1695e-04, 2.9947e-15, 5.6164e-24, 6.4353e-03, 1.0323e-10, 3.2459e-12,\n",
       "         1.4123e-18, 2.8439e-06, 9.5557e-09, 2.9738e-19, 3.0809e-06, 3.5601e-23,\n",
       "         3.3558e-11, 5.6912e-01, 3.7505e-21],\n",
       "        [1.2824e-08, 4.7736e-12, 6.4878e-31, 3.4058e-19, 9.0286e-28, 7.3304e-14,\n",
       "         1.4065e-25, 7.7113e-23, 2.2929e-22, 2.2235e-27, 8.7217e-07, 6.1552e-15,\n",
       "         1.6313e-02, 2.6638e-07, 4.2773e-11, 5.6812e-12, 1.7715e-18, 1.5601e-22,\n",
       "         2.6979e-25, 9.8369e-01, 7.6495e-13, 9.4641e-25, 3.0743e-08, 4.5650e-25,\n",
       "         1.2543e-17, 3.4394e-16, 5.0577e-17],\n",
       "        [3.4104e-08, 6.5361e-14, 4.1929e-16, 7.9430e-09, 2.7652e-33, 1.8524e-05,\n",
       "         1.4021e-03, 3.9726e-05, 1.5912e-08, 1.2339e-13, 1.8679e-15, 2.6956e-18,\n",
       "         9.2298e-09, 1.7039e-02, 6.8765e-01, 2.0990e-11, 1.5883e-15, 1.2111e-21,\n",
       "         3.0904e-14, 2.8510e-01, 8.7487e-03, 1.5532e-19, 7.0375e-11, 4.7679e-10,\n",
       "         8.3825e-11, 6.0440e-12, 2.1765e-10],\n",
       "        [4.4588e-27, 8.3673e-18, 3.0949e-01, 6.9030e-01, 1.3537e-28, 5.3224e-17,\n",
       "         1.2637e-04, 1.7399e-05, 3.1966e-17, 5.8359e-20, 2.4029e-38, 1.0080e-25,\n",
       "         1.4645e-29, 1.9841e-27, 2.0691e-23, 1.8369e-09, 3.1619e-26, 7.7318e-17,\n",
       "         9.4703e-13, 7.4337e-29, 1.0276e-17, 2.0656e-18, 4.1160e-25, 3.3889e-11,\n",
       "         8.8926e-17, 6.4135e-05, 3.0545e-24]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7795e-23, 2.9947e-15, 2.6638e-07, 6.5361e-14, 4.4588e-27])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(5),Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38.3102)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative log likelihood\n",
    "-probs[torch.arange(5),Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n",
      "target: tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 15],\n",
      "        [ 0, 15, 12],\n",
      "        [15, 12,  9],\n",
      "        [12,  9, 22],\n",
      "        [ 9, 22,  9],\n",
      "        [22,  9,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  1],\n",
      "        [ 0,  1, 22],\n",
      "        [ 1, 22,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  9],\n",
      "        [ 0,  9, 19],\n",
      "        [ 9, 19,  1],\n",
      "        [19,  1,  2],\n",
      "        [ 1,  2,  5],\n",
      "        [ 2,  5, 12],\n",
      "        [ 5, 12, 12],\n",
      "        [12, 12,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 19],\n",
      "        [ 0, 19, 15],\n",
      "        [19, 15, 16],\n",
      "        [15, 16,  8],\n",
      "        [16,  8,  9],\n",
      "        [ 8,  9,  1]])\n",
      "label tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "# Rewriting the code to make it work with dataset containing first 5 words\n",
    "# build the dataset\n",
    "block_size= 3\n",
    "\n",
    "# The X are the input for the neural net and Y is the labels corresponding to X\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix= stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] \n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "print('target:',X)\n",
    "print('label',Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproduciability\n",
    "C = torch.randn(27,2,generator=g)\n",
    "W1 = torch.randn(6,100,generator=g)\n",
    "b1 = torch.randn(100,generator=g)\n",
    "W2 = torch.randn(100,27,generator=g)\n",
    "b2 = torch.randn(27,generator=g)\n",
    "\n",
    "parameters = [C,W1,b1,W2,b2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] #(32,3,2)\n",
    "h = torch.tanh(emb.view(-1,6) @ W1+b1) # (32,100)\n",
    "logits = h @ W2 + b2 # (32,27)\n",
    "counts = logits.exp()\n",
    "probs = counts/counts.sum(1,keepdim=True)\n",
    "loss = -probs[torch.arange(32),Y].log().mean()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introducing Cross Entropy\n",
    "F.cross_entropy(logits,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
